{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameter Tuning .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6Bc1DeEm06z"
      },
      "source": [
        "# Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lMjfF7DQ8nV",
        "outputId": "6202c69c-8955-4a30-ecd3-ddf6dc25728d"
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.datasets import load_files\n",
        "nltk.download('stopwords')\n",
        "import pickle\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "import statsmodels.api as sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZKqvgV2m5PF"
      },
      "source": [
        "# loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "HivoZr48RJYS",
        "outputId": "be4cfd30-8955-41e2-e87e-671e681d124c"
      },
      "source": [
        "data = pd.read_csv(\"DataML.csv\")\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Excellent look</td>\n",
              "      <td>Recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good product</td>\n",
              "      <td>Recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nice dress</td>\n",
              "      <td>Recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LOVEd THIS clothS</td>\n",
              "      <td>Recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Really the product was as it is in the photo I...</td>\n",
              "      <td>Recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>Average,Poor quality, black color faded with 1...</td>\n",
              "      <td>Not Recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>Fabric is not good not cottoandit's a mix of f...</td>\n",
              "      <td>Not Recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>Product Not justify to the price - overpriced,...</td>\n",
              "      <td>Not Recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>Be honest Amazon.,Not satisfied.  Looks totall...</td>\n",
              "      <td>Not Recommended</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>.,Material  not as good as expected</td>\n",
              "      <td>Not Recommended</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>600 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Review            label\n",
              "0                                       Excellent look      Recommended\n",
              "1                                         Good product      Recommended\n",
              "2                                           Nice dress      Recommended\n",
              "3                                    LOVEd THIS clothS      Recommended\n",
              "4    Really the product was as it is in the photo I...      Recommended\n",
              "..                                                 ...              ...\n",
              "595  Average,Poor quality, black color faded with 1...  Not Recommended\n",
              "596  Fabric is not good not cottoandit's a mix of f...  Not Recommended\n",
              "597  Product Not justify to the price - overpriced,...  Not Recommended\n",
              "598  Be honest Amazon.,Not satisfied.  Looks totall...  Not Recommended\n",
              "599                .,Material  not as good as expected  Not Recommended\n",
              "\n",
              "[600 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa606lrzm-v0"
      },
      "source": [
        "# Making X and y variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roO0YkuTRunv"
      },
      "source": [
        "X, y = data.Review, data.label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnWpsadHnEQP"
      },
      "source": [
        "# stemming, lemmatisation, stop words removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-RxgPpCRlGo"
      },
      "source": [
        "documents = []\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "stemmer = WordNetLemmatizer()\n",
        "\n",
        "for sen in range(0, len(X)):\n",
        "    # Remove all the special characters\n",
        "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
        "    \n",
        "    # remove all single characters\n",
        "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
        "    \n",
        "    # Remove single characters from the start\n",
        "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
        "    \n",
        "    # Substituting multiple spaces with single space\n",
        "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
        "    \n",
        "    # Removing prefixed 'b'\n",
        "    document = re.sub(r'^b\\s+', '', document)\n",
        "    \n",
        "    # Converting to Lowercase\n",
        "    document = document.lower()\n",
        "    \n",
        "    # Lemmatization\n",
        "    document = document.split()\n",
        "\n",
        "    document = [stemmer.lemmatize(word) for word in document]\n",
        "    document = ' '.join(document)\n",
        "    \n",
        "    documents.append(document)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83TdK3Sxwio6"
      },
      "source": [
        "# bag of words model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iY3bw9KSHvJ"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
        "X = vectorizer.fit_transform(documents).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnf3rWXkwoC3"
      },
      "source": [
        "# TFIDF Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZXGkPfeS73E"
      },
      "source": [
        "# from sklearn.feature_extraction.text import TfidfTransformer\n",
        "# tfidfconverter = TfidfTransformer()\n",
        "# X = tfidfconverter.fit_transform(X).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFP5mMvkSQS4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9szeZpOT1uh"
      },
      "source": [
        "# Multi layer Perceptron Implementaion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvq5gc0CT7mW"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(max_iter=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiVta0_Llc5q"
      },
      "source": [
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (150,100,50),(200,250,100)],\n",
        "    'activation': ['tanh', 'relu','logistic'],\n",
        "    'solver': ['sgd', 'adam','lbfgs'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'learning_rate': ['constant','adaptive','invscaling'],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wToa5l3Jm3cI",
        "outputId": "e7ac5cb8-7726-4e44-eeb8-7c1834463e27"
      },
      "source": [
        "# Best paramete set\n",
        "print('Best parameters found:\\n', clf.best_params_)\n",
        "\n",
        "# All results\n",
        "means = clf.cv_results_['mean_test_score']\n",
        "stds = clf.cv_results_['std_test_score']\n",
        "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters found:\n",
            " {'solver': 'lbfgs', 'learning_rate': 'invscaling', 'hidden_layer_sizes': (150, 100, 50), 'alpha': 0.0001, 'activation': 'tanh'}\n",
            "0.858 (+/-0.051) for {'solver': 'lbfgs', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (150, 100, 50), 'alpha': 0.05, 'activation': 'tanh'}\n",
            "0.858 (+/-0.039) for {'solver': 'lbfgs', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (200, 250, 100), 'alpha': 0.0001, 'activation': 'relu'}\n",
            "0.850 (+/-0.044) for {'solver': 'lbfgs', 'learning_rate': 'constant', 'hidden_layer_sizes': (50, 100, 50), 'alpha': 0.0001, 'activation': 'relu'}\n",
            "0.852 (+/-0.031) for {'solver': 'adam', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50, 50, 50), 'alpha': 0.0001, 'activation': 'relu'}\n",
            "0.765 (+/-0.089) for {'solver': 'sgd', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50, 100, 50), 'alpha': 0.05, 'activation': 'tanh'}\n",
            "0.504 (+/-0.190) for {'solver': 'sgd', 'learning_rate': 'invscaling', 'hidden_layer_sizes': (50, 100, 50), 'alpha': 0.05, 'activation': 'relu'}\n",
            "0.842 (+/-0.060) for {'solver': 'lbfgs', 'learning_rate': 'constant', 'hidden_layer_sizes': (50, 100, 50), 'alpha': 0.0001, 'activation': 'tanh'}\n",
            "0.869 (+/-0.041) for {'solver': 'lbfgs', 'learning_rate': 'invscaling', 'hidden_layer_sizes': (150, 100, 50), 'alpha': 0.0001, 'activation': 'tanh'}\n",
            "0.510 (+/-0.006) for {'solver': 'sgd', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (200, 250, 100), 'alpha': 0.0001, 'activation': 'logistic'}\n",
            "0.869 (+/-0.035) for {'solver': 'adam', 'learning_rate': 'constant', 'hidden_layer_sizes': (50, 50, 50), 'alpha': 0.05, 'activation': 'relu'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSh790bOnWpj",
        "outputId": "f7349074-5256-4681-95ac-4c98bda93cb1"
      },
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
        "print('Results on the test set:')\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results on the test set:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not Recommended       0.86      0.86      0.86        65\n",
            "    Recommended       0.84      0.84      0.84        55\n",
            "\n",
            "       accuracy                           0.85       120\n",
            "      macro avg       0.85      0.85      0.85       120\n",
            "   weighted avg       0.85      0.85      0.85       120\n",
            "\n",
            "0.85\n",
            "[[56  9]\n",
            " [ 9 46]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1iypPmhzqL5",
        "outputId": "e9a777ba-6197-4370-93bb-12e2a3a002b4"
      },
      "source": [
        "TN= 47\n",
        "FP= 12\n",
        "specificity= TN/(TN+FP)\n",
        "print(specificity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7966101694915254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4IiASmOUE0r"
      },
      "source": [
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "# vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
        "# X = vectorizer.fit_transform(documents).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSjC2RTyUHrj"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidfconverter = TfidfTransformer()\n",
        "X = tfidfconverter.fit_transform(X).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQkVBIA0UKSZ"
      },
      "source": [
        "clffff = MLPClassifier(hidden_layer_sizes=(150,100,50), max_iter=300,activation = 'relu',solver='adam',random_state=1).fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYvrSZzTUOTi",
        "outputId": "4941641d-8570-4612-927c-9a8aa88fadb0"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(clffff, X, y, cv=10)\n",
        "print('Cross-Validation Accuracy Scores', scores)\n",
        "print(scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-Validation Accuracy Scores [0.73333333 0.83333333 0.81666667 0.81666667 0.85       0.91666667\n",
            " 0.7        0.86666667 0.88333333 0.9       ]\n",
            "0.8316666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaSzamA_UQw0"
      },
      "source": [
        "y_pred = clffff.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gDXtzdhUS7L",
        "outputId": "80faa26a-ad5a-493b-d9fc-1ba7d170c54d"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[58  7]\n",
            " [ 9 46]]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not Recommended       0.87      0.89      0.88        65\n",
            "    Recommended       0.87      0.84      0.85        55\n",
            "\n",
            "       accuracy                           0.87       120\n",
            "      macro avg       0.87      0.86      0.87       120\n",
            "   weighted avg       0.87      0.87      0.87       120\n",
            "\n",
            "0.8666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6K01339UV08",
        "outputId": "1164fbd9-772f-4e36-efff-eb286f3df338"
      },
      "source": [
        "TN= 46\n",
        "FP= 7\n",
        "specificity= TN/(TN+FP)\n",
        "print(specificity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8679245283018868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15b4xQNPaXmT"
      },
      "source": [
        "# XG Boost Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U19a1hZaj7J"
      },
      "source": [
        "from xgboost import XGBClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jyh60q6hEs7"
      },
      "source": [
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGl4BtC76cuv"
      },
      "source": [
        "ITERATIONS=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxJinU_354N0"
      },
      "source": [
        "bayes_cv_tuner = BayesSearchCV(\n",
        "    estimator = xgb.XGBClassifier(\n",
        "        n_jobs = 1,\n",
        "        objective = 'binary:logistic',\n",
        "        eval_metric = 'auc',\n",
        "        silent=1,\n",
        "        tree_method='approx'\n",
        "    ),\n",
        "    search_spaces = {\n",
        "        \"subsample\":[0.5, 0.75, 1],\n",
        "\"colsample_bytree\":[0.5, 0.75, 1],\n",
        "\"max_depth\":[2, 6, 12],\n",
        "\"min_child_weight\":[1,5,15],\n",
        "\"learning_rate\":[0.3, 0.1, 0.03],\n",
        "\"n_estimators\":[100],\n",
        " 'reg_alpha': [1.1, 1.2, 1.3],\n",
        " \"colsample_bylevel\":[0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "    },    \n",
        "    scoring = 'roc_auc',\n",
        "    cv = StratifiedKFold(\n",
        "        n_splits=3,\n",
        "        shuffle=True,\n",
        "        random_state=42\n",
        "    ),\n",
        "    n_jobs = 3,\n",
        "    n_iter = ITERATIONS,   \n",
        "    verbose = 0,\n",
        "    refit = True,\n",
        "    random_state = 42\n",
        ")\n",
        "def status_print(optim_result):\n",
        "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
        "    \n",
        "    # Get all the models tested so far in DataFrame format\n",
        "    all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n",
        "    \n",
        "    # Get current parameters and the best parameters    \n",
        "    best_params = pd.Series(bayes_cv_tuner.best_params_)\n",
        "    print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(\n",
        "        len(all_models),\n",
        "        np.round(bayes_cv_tuner.best_score_, 4),\n",
        "        bayes_cv_tuner.best_params_\n",
        "    ))\n",
        "    \n",
        "    # Save all model results\n",
        "    clf_name = bayes_cv_tuner.estimator.__class__.__name__\n",
        "    all_models.to_csv(clf_name+\"_cv_results.csv\")\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceVxJKxF6kU9",
        "outputId": "250f95d9-3751-4cd0-999c-d932ad0ce4eb"
      },
      "source": [
        "result = bayes_cv_tuner.fit(X_train, y_train, callback=status_print)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model #1\n",
            "Best ROC-AUC: 0.7859\n",
            "Best params: OrderedDict([('colsample_bylevel', 0.6), ('colsample_bytree', 0.75), ('learning_rate', 0.3), ('max_depth', 6), ('min_child_weight', 5), ('n_estimators', 100), ('reg_alpha', 1.2), ('subsample', 0.75)])\n",
            "\n",
            "Model #2\n",
            "Best ROC-AUC: 0.7859\n",
            "Best params: OrderedDict([('colsample_bylevel', 0.6), ('colsample_bytree', 0.75), ('learning_rate', 0.3), ('max_depth', 6), ('min_child_weight', 5), ('n_estimators', 100), ('reg_alpha', 1.2), ('subsample', 0.75)])\n",
            "\n",
            "Model #3\n",
            "Best ROC-AUC: 0.8766\n",
            "Best params: OrderedDict([('colsample_bylevel', 0.7), ('colsample_bytree', 1.0), ('learning_rate', 0.03), ('max_depth', 6), ('min_child_weight', 1), ('n_estimators', 100), ('reg_alpha', 1.1), ('subsample', 1.0)])\n",
            "\n",
            "Model #4\n",
            "Best ROC-AUC: 0.8766\n",
            "Best params: OrderedDict([('colsample_bylevel', 0.7), ('colsample_bytree', 1.0), ('learning_rate', 0.03), ('max_depth', 6), ('min_child_weight', 1), ('n_estimators', 100), ('reg_alpha', 1.1), ('subsample', 1.0)])\n",
            "\n",
            "Model #5\n",
            "Best ROC-AUC: 0.8766\n",
            "Best params: OrderedDict([('colsample_bylevel', 0.7), ('colsample_bytree', 1.0), ('learning_rate', 0.03), ('max_depth', 6), ('min_child_weight', 1), ('n_estimators', 100), ('reg_alpha', 1.1), ('subsample', 1.0)])\n",
            "\n",
            "Model #6\n",
            "Best ROC-AUC: 0.8766\n",
            "Best params: OrderedDict([('colsample_bylevel', 0.7), ('colsample_bytree', 1.0), ('learning_rate', 0.03), ('max_depth', 6), ('min_child_weight', 1), ('n_estimators', 100), ('reg_alpha', 1.1), ('subsample', 1.0)])\n",
            "\n",
            "Model #7\n",
            "Best ROC-AUC: 0.8766\n",
            "Best params: OrderedDict([('colsample_bylevel', 0.7), ('colsample_bytree', 1.0), ('learning_rate', 0.03), ('max_depth', 6), ('min_child_weight', 1), ('n_estimators', 100), ('reg_alpha', 1.1), ('subsample', 1.0)])\n",
            "\n",
            "Model #8\n",
            "Best ROC-AUC: 0.8766\n",
            "Best params: OrderedDict([('colsample_bylevel', 0.7), ('colsample_bytree', 1.0), ('learning_rate', 0.03), ('max_depth', 6), ('min_child_weight', 1), ('n_estimators', 100), ('reg_alpha', 1.1), ('subsample', 1.0)])\n",
            "\n",
            "Model #9\n",
            "Best ROC-AUC: 0.8766\n",
            "Best params: OrderedDict([('colsample_bylevel', 0.7), ('colsample_bytree', 1.0), ('learning_rate', 0.03), ('max_depth', 6), ('min_child_weight', 1), ('n_estimators', 100), ('reg_alpha', 1.1), ('subsample', 1.0)])\n",
            "\n",
            "Model #10\n",
            "Best ROC-AUC: 0.8766\n",
            "Best params: OrderedDict([('colsample_bylevel', 0.7), ('colsample_bytree', 1.0), ('learning_rate', 0.03), ('max_depth', 6), ('min_child_weight', 1), ('n_estimators', 100), ('reg_alpha', 1.1), ('subsample', 1.0)])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "706hJSTrFELR"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80LfKvzQ8w8z"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ougwLreg-Gg"
      },
      "source": [
        "xgb_model = xgb.XGBClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwY5eh3-hI26"
      },
      "source": [
        "param_dist = {\n",
        "        'n_estimators':range(80,200,4),\n",
        "        'max_depth':range(2,15,1),\n",
        "        'learning_rate':np.linspace(0.01,2,20),\n",
        "        'subsample':np.linspace(0.7,0.9,20),\n",
        "        'colsample_bytree':np.linspace(0.5,0.98,10),\n",
        "        'min_child_weight':range(1,9,1)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBwmyGsvhKTb"
      },
      "source": [
        "grid = GridSearchCV(xgb_model,param_dist,cv = 3,scoring = 'neg_log_loss',n_jobs = -1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "Nrv65EGfvH2X",
        "outputId": "1c5e4496-175b-4598-c9be-658725ec5c40"
      },
      "source": [
        "best_estimator = grid.best_estimator_\n",
        "print(best_estimator)\n",
        " #Output the accuracy of the optimal trainer\n",
        "print(grid.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-a036a3658bfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m  \u001b[0;31m#Output the accuracy of the optimal trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_estimator_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9uBvi4C9dph",
        "outputId": "e9596da6-8e22-42d0-8113-8493ff4ff8b7"
      },
      "source": [
        "best_score = bayes_cv_tuner.best_score_\n",
        "best_params = bayes_cv_tuner.best_params_\n",
        "print(\"Best score: {}\".format(best_score))\n",
        "print(\"Best params: \")\n",
        "for param_name in sorted(best_params.keys()):\n",
        "    print('%s: %r' % (param_name, best_params[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.8766311692111837\n",
            "Best params: \n",
            "colsample_bylevel: 0.7\n",
            "colsample_bytree: 1.0\n",
            "learning_rate: 0.03\n",
            "max_depth: 6\n",
            "min_child_weight: 1\n",
            "n_estimators: 100\n",
            "reg_alpha: 1.1\n",
            "subsample: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMl6ZTqHarsC"
      },
      "source": [
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "# vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
        "# X = vectorizer.fit_transform(documents).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fYwEwzbavqQ"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidfconverter = TfidfTransformer()\n",
        "X = tfidfconverter.fit_transform(X).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzSeKOq_avy3",
        "outputId": "97469564-d0e7-4526-c116-35354e179ecb"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(xgboost , X, y, cv=10)\n",
        "print('Cross-Validation Accuracy Scores', scores)\n",
        "print(scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-Validation Accuracy Scores [0.66666667 0.73333333 0.83333333 0.83333333 0.81666667 0.88333333\n",
            " 0.71666667 0.83333333 0.86666667 0.85      ]\n",
            "0.8033333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYCLJ7kLbkVp"
      },
      "source": [
        "y_pred = bayes_cv_tuner.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQX0EcHbbddw",
        "outputId": "744ce35e-023d-48da-8c70-cdefcc76f97c"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[45 20]\n",
            " [ 6 49]]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not Recommended       0.88      0.69      0.78        65\n",
            "    Recommended       0.71      0.89      0.79        55\n",
            "\n",
            "       accuracy                           0.78       120\n",
            "      macro avg       0.80      0.79      0.78       120\n",
            "   weighted avg       0.80      0.78      0.78       120\n",
            "\n",
            "0.7833333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDrHDhDHqfLm",
        "outputId": "f0eb897f-d3e3-46ff-a846-5370737d3831"
      },
      "source": [
        "TN= 49\n",
        "FP= 20\n",
        "specificity= TN/(TN+FP)\n",
        "print(specificity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7101449275362319\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}